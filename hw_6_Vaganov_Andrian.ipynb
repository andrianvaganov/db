{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Файл с dag в оригинале выполнен как .py файл. Сохранён здесь в виде ipynb чтобы можно было добавить скрины об успешном выполнении из airflow\n",
    "\n",
    "from airflow import DAG\n",
    "from airflow.providers.common.sql.operators.sql import SQLExecuteQueryOperator\n",
    "from airflow.providers.postgres.hooks.postgres import PostgresHook\n",
    "from airflow.providers.standard.operators.python import PythonOperator\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "from airflow.providers.standard.operators.empty import EmptyOperator\n",
    "import logging\n",
    "\n",
    "default_args = {\n",
    "    'owner': 'dags',\n",
    "    'depends_on_past': False,\n",
    "    'start_date': datetime(2025, 12, 20),\n",
    "    'email_on_failure': False,\n",
    "    'email_on_retry': False,\n",
    "    'retries': 1,\n",
    "    'retry_delay': timedelta(minutes=5),\n",
    "}\n",
    "\n",
    "\n",
    "def load_customers_to_postgres(**context):\n",
    "    df_customers = pd.read_csv('/opt/airflow/dags/customer.csv', sep=';')\n",
    "    postgres_hook = PostgresHook(postgres_conn_id='postgres')\n",
    "\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS customers (\n",
    "        customer_id INTEGER PRIMARY KEY,\n",
    "        first_name VARCHAR(100),\n",
    "        last_name VARCHAR(100),\n",
    "        gender VARCHAR(20),\n",
    "        dob DATE,\n",
    "        job_title VARCHAR(200),\n",
    "        job_industry_category VARCHAR(100),\n",
    "        wealth_segment VARCHAR(50),\n",
    "        deceased_indicator VARCHAR(1),\n",
    "        owns_car VARCHAR(3),\n",
    "        address TEXT,\n",
    "        postcode VARCHAR(10),\n",
    "        state VARCHAR(50),\n",
    "        country VARCHAR(50),\n",
    "        property_valuation INTEGER,\n",
    "        load_date DATE DEFAULT CURRENT_DATE,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "    postgres_hook.run(create_table_sql)\n",
    "\n",
    "    create_indexes_sql = [\n",
    "        \"CREATE INDEX IF NOT EXISTS idx_customers_dob ON customers(dob);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS idx_customers_state ON customers(state);\",\n",
    "        \"CREATE INDEX IF NOT EXISTS idx_customers_postcode ON customers(postcode);\"\n",
    "    ]\n",
    "\n",
    "    for sql in create_indexes_sql:\n",
    "        try:\n",
    "            postgres_hook.run(sql)\n",
    "        except Exception as e:\n",
    "            logging.info(f\"Индекс уже существует: {e}\")\n",
    "\n",
    "    df_customers.to_sql(\n",
    "        'customers',\n",
    "        postgres_hook.get_sqlalchemy_engine(),\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "    logging.info(f\"Загружено {len(df_customers)} записей в таблицу customers\")\n",
    "    return len(df_customers)\n",
    "\n",
    "\n",
    "def load_order_items_to_postgres(**context):\n",
    "    df_order_items = pd.read_csv('/opt/airflow/dags/order_items.csv')\n",
    "    postgres_hook = PostgresHook(postgres_conn_id='postgres')\n",
    "\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS order_items (\n",
    "    order_item_id INTEGER PRIMARY KEY,\n",
    "    order_id INTEGER,\n",
    "    product_id INTEGER,\n",
    "    quantity DECIMAL(10, 2),\n",
    "    item_list_price_at_sale DECIMAL(10, 2),\n",
    "    item_standard_cost_at_sale DECIMAL(10, 2),\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    postgres_hook.run(create_table_sql)\n",
    "    df_order_items.to_sql(\n",
    "        'order_items',\n",
    "        postgres_hook.get_sqlalchemy_engine(),\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "    logging.info(f\"Загружено {len(df_order_items)} записей в таблицу order_items\")\n",
    "    return len(df_order_items)\n",
    "\n",
    "\n",
    "def load_orders_to_postgres(**context):\n",
    "    df_orders = pd.read_csv('/opt/airflow/dags/orders.csv')\n",
    "    postgres_hook = PostgresHook(postgres_conn_id='postgres')\n",
    "\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS orders (\n",
    "    order_id INTEGER PRIMARY KEY,\n",
    "    customer_id INTEGER,\n",
    "    order_date DATE,\n",
    "    online_order BOOLEAN,\n",
    "    order_status VARCHAR(50),\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    postgres_hook.run(create_table_sql)\n",
    "    df_orders.to_sql(\n",
    "        'orders',\n",
    "        postgres_hook.get_sqlalchemy_engine(),\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "    logging.info(f\"Загружено {len(df_orders)} записей в таблицу orders\")\n",
    "    return len(df_orders)\n",
    "\n",
    "\n",
    "def load_product_to_postgres(**context):\n",
    "    df_product = pd.read_csv('/opt/airflow/dags/product.csv')\n",
    "    postgres_hook = PostgresHook(postgres_conn_id='postgres')\n",
    "\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS product (\n",
    "    product_id INTEGER PRIMARY KEY,\n",
    "    brand VARCHAR(100),\n",
    "    product_line VARCHAR(50),\n",
    "    product_class VARCHAR(50),\n",
    "    product_size VARCHAR(50),\n",
    "    list_price DECIMAL(10, 2),\n",
    "    standard_cost DECIMAL(10, 2),\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    postgres_hook.run(create_table_sql)\n",
    "    df_product.to_sql(\n",
    "        'product',\n",
    "        postgres_hook.get_sqlalchemy_engine(),\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "    logging.info(f\"Загружено {len(df_product)} записей в таблицу product\")\n",
    "    return len(df_product)\n",
    "\n",
    "\n",
    "def save_query1_result(**context):\n",
    "    hook = PostgresHook(postgres_conn_id='postgres')\n",
    "    query1_sql = \"\"\"\n",
    "    WITH customer_transactions AS (\n",
    "        SELECT\n",
    "            c.customer_id,\n",
    "            c.first_name,\n",
    "            c.last_name,\n",
    "            COALESCE(SUM(oi.quantity * oi.item_list_price_at_sale), 0) as total_transaction_amount\n",
    "        FROM customers c\n",
    "        LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "        LEFT JOIN order_items oi ON o.order_id = oi.order_id\n",
    "        GROUP BY c.customer_id, c.first_name, c.last_name\n",
    "    ),\n",
    "    ranked_min AS (\n",
    "        SELECT\n",
    "            customer_id,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            total_transaction_amount,\n",
    "            ROW_NUMBER() OVER (ORDER BY total_transaction_amount ASC) as min_rank\n",
    "        FROM customer_transactions\n",
    "        WHERE total_transaction_amount > 0\n",
    "    ),\n",
    "    ranked_max AS (\n",
    "        SELECT\n",
    "            customer_id,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            total_transaction_amount,\n",
    "            ROW_NUMBER() OVER (ORDER BY total_transaction_amount DESC) as max_rank\n",
    "        FROM customer_transactions\n",
    "    )\n",
    "    SELECT\n",
    "        'MIN' as transaction_type,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        total_transaction_amount\n",
    "    FROM ranked_min\n",
    "    WHERE min_rank <= 3\n",
    "    UNION ALL\n",
    "    SELECT\n",
    "        'MAX' as transaction_type,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        total_transaction_amount\n",
    "    FROM ranked_max\n",
    "    WHERE max_rank <= 3\n",
    "    ORDER BY transaction_type, total_transaction_amount;\n",
    "    \"\"\"\n",
    "    result_df = hook.get_pandas_df(sql=query1_sql)\n",
    "    output_path = '/opt/airflow/dags/top3_min_max_transactions.csv'\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    logging.info(f\"Запрос 1 выполнен. Найдено записей: {len(result_df)}\")\n",
    "    return len(result_df)\n",
    "\n",
    "\n",
    "def save_query2_result(**context):\n",
    "    hook = PostgresHook(postgres_conn_id='postgres')\n",
    "    query2_sql = \"\"\"\n",
    "    WITH customer_revenue AS (\n",
    "        SELECT\n",
    "            c.customer_id,\n",
    "            c.first_name,\n",
    "            c.last_name,\n",
    "            c.wealth_segment,\n",
    "            COALESCE(SUM(oi.quantity * oi.item_list_price_at_sale), 0) as total_revenue\n",
    "        FROM customers c\n",
    "        LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
    "        LEFT JOIN order_items oi ON o.order_id = oi.order_id\n",
    "        GROUP BY c.customer_id, c.first_name, c.last_name, c.wealth_segment\n",
    "    ),\n",
    "    ranked_customers AS (\n",
    "        SELECT\n",
    "            first_name,\n",
    "            last_name,\n",
    "            wealth_segment,\n",
    "            total_revenue,\n",
    "            ROW_NUMBER() OVER (\n",
    "                PARTITION BY wealth_segment\n",
    "                ORDER BY total_revenue DESC\n",
    "            ) as rank_in_segment\n",
    "        FROM customer_revenue\n",
    "    )\n",
    "    SELECT\n",
    "        first_name,\n",
    "        last_name,\n",
    "        wealth_segment,\n",
    "        total_revenue,\n",
    "        rank_in_segment\n",
    "    FROM ranked_customers\n",
    "    WHERE rank_in_segment <= 5\n",
    "    ORDER BY wealth_segment, rank_in_segment;\n",
    "    \"\"\"\n",
    "    result_df = hook.get_pandas_df(sql=query2_sql)\n",
    "    output_path = '/opt/airflow/dags/top5_wealth_segment.csv'\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    logging.info(f\"Запрос 2 выполнен. Найдено записей: {len(result_df)}\")\n",
    "    return len(result_df)\n",
    "\n",
    "\n",
    "def check_query1_result(**context):\n",
    "    ti = context['ti']\n",
    "    row_count = ti.xcom_pull(task_ids='save_query1_result')\n",
    "    if row_count == 0:\n",
    "        logging.warning(\"ВНИМАНИЕ: Запрос 1 вернул 0 строк!\")\n",
    "        return False\n",
    "    else:\n",
    "        logging.info(f\"Запрос 1 прошел проверку: {row_count} строк\")\n",
    "        return True\n",
    "\n",
    "\n",
    "def check_query2_result(**context):\n",
    "    ti = context['ti']\n",
    "    row_count = ti.xcom_pull(task_ids='save_query2_result')\n",
    "    if row_count == 0:\n",
    "        logging.warning(\"ВНИМАНИЕ: Запрос 2 вернул 0 строк!\")\n",
    "        return False\n",
    "    else:\n",
    "        logging.info(f\"Запрос 2 прошел проверку: {row_count} строк\")\n",
    "        return True\n",
    "\n",
    "\n",
    "def final_dag_status_check(**context):\n",
    "    ti = context['ti']\n",
    "\n",
    "    results = {\n",
    "        'load_customers': ti.xcom_pull(task_ids='load_csv_data_cust_2'),\n",
    "        'load_order_items': ti.xcom_pull(task_ids='load_csv_data_oi'),\n",
    "        'load_orders': ti.xcom_pull(task_ids='load_csv_data_o'),\n",
    "        'load_product': ti.xcom_pull(task_ids='load_csv_data_p'),\n",
    "        'query1_check': ti.xcom_pull(task_ids='check_query1_result'),\n",
    "        'query2_check': ti.xcom_pull(task_ids='check_query2_result')\n",
    "    }\n",
    "\n",
    "    all_success = all(results.values())\n",
    "\n",
    "    log_message = f\"\"\"\n",
    "    Статус выполнения:\n",
    "    - Загрузка customers: {results['load_customers']} записей\n",
    "    - Загрузка order_items: {results['load_order_items']} записей\n",
    "    - Загрузка orders: {results['load_orders']} записей\n",
    "    - Загрузка product: {results['load_product']} записей\n",
    "    - Проверка запроса 1: {'ПРОЙДЕНА' if results['query1_check'] else 'НЕ ПРОЙДЕНА (0 строк)'}\n",
    "    - Проверка запроса 2: {'ПРОЙДЕНА' if results['query2_check'] else 'НЕ ПРОЙДЕНА (0 строк)'}\n",
    "    \"\"\"\n",
    "\n",
    "    if all_success:\n",
    "        success_message = \"\"\"\n",
    "    DAG ВЫПОЛНЕН УСПЕШНО!\n",
    "    Все задачи выполнены, аналитические запросы вернули данные.\n",
    "    Результаты сохранены в файлы:\n",
    "    - /opt/airflow/dags/top3_min_max_transactions.csv\n",
    "    - /opt/airflow/dags/top5_wealth_segment.csv\n",
    "        \"\"\"\n",
    "        logging.info(log_message)\n",
    "        logging.info(success_message)\n",
    "        return \"SUCCESS\"\n",
    "    else:\n",
    "        failed_tasks = [key for key, value in results.items() if not value and value is not False]\n",
    "        error_message = f\"\"\"\n",
    "    DAG ВЫПОЛНЕН С ОШИБКАМИ!\n",
    "    Не пройдены проверки: {', '.join(failed_tasks) if failed_tasks else 'Одна или несколько проверок не пройдены'}\n",
    "        \"\"\"\n",
    "        logging.warning(log_message)\n",
    "        logging.warning(error_message)\n",
    "        return \"FAILED\"\n",
    "\n",
    "\n",
    "with DAG(\n",
    "        'daily_csv_to_postgres_',\n",
    "        default_args=default_args,\n",
    "        description='Ежедневная загрузка CSV в PostgreSQL и аналитические запросы',\n",
    "        schedule='*/5 * * * *',\n",
    "        catchup=False,\n",
    "        tags=['csv', 'postgres', 'etl', 'analytics'],\n",
    ") as dag:\n",
    "    start = EmptyOperator(task_id='start')\n",
    "\n",
    "    load_data_cust = PythonOperator(\n",
    "        task_id='load_csv_data_cust_2',\n",
    "        python_callable=load_customers_to_postgres\n",
    "    )\n",
    "\n",
    "    load_data_oi = PythonOperator(\n",
    "        task_id='load_csv_data_oi',\n",
    "        python_callable=load_order_items_to_postgres\n",
    "    )\n",
    "\n",
    "    load_data_o = PythonOperator(\n",
    "        task_id='load_csv_data_o',\n",
    "        python_callable=load_orders_to_postgres\n",
    "    )\n",
    "\n",
    "    load_data_p = PythonOperator(\n",
    "        task_id='load_csv_data_p',\n",
    "        python_callable=load_product_to_postgres\n",
    "    )\n",
    "\n",
    "    save_result1_task = PythonOperator(\n",
    "        task_id='save_query1_result',\n",
    "        python_callable=save_query1_result,\n",
    "    )\n",
    "\n",
    "    save_result2_task = PythonOperator(\n",
    "        task_id='save_query2_result',\n",
    "        python_callable=save_query2_result,\n",
    "    )\n",
    "\n",
    "    check_result1_task = PythonOperator(\n",
    "        task_id='check_query1_result',\n",
    "        python_callable=check_query1_result,\n",
    "    )\n",
    "\n",
    "    check_result2_task = PythonOperator(\n",
    "        task_id='check_query2_result',\n",
    "        python_callable=check_query2_result,\n",
    "    )\n",
    "\n",
    "    final_status_task = PythonOperator(\n",
    "        task_id='final_dag_status_check',\n",
    "        python_callable=final_dag_status_check,\n",
    "    )\n",
    "\n",
    "    end = EmptyOperator(task_id='end')\n",
    "\n",
    "    start >> [load_data_cust, load_data_oi, load_data_o, load_data_p]\n",
    "\n",
    "    for load_task in [load_data_cust, load_data_oi, load_data_o, load_data_p]:\n",
    "        load_task >> save_result1_task\n",
    "        load_task >> save_result2_task\n",
    "\n",
    "    save_result1_task >> check_result1_task\n",
    "    save_result2_task >> check_result2_task\n",
    "\n",
    "    check_result1_task >> final_status_task\n",
    "    check_result2_task >> final_status_task\n",
    "\n",
    "    final_status_task >> end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
